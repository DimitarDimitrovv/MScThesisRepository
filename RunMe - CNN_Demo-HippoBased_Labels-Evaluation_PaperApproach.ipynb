{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StackOverflowData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:20:38.861924Z",
     "start_time": "2019-06-27T22:20:38.845516Z"
    },
    "code_folding": [
     6
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "# if you have labels\n",
    "\n",
    "\n",
    "'''\n",
    "    The idea of the function below (map_label) is a simplified approach to what they did in the initial paper. \n",
    "    They used the so called Hungarian method in order to optimize the labeling. The optimization is based on the\n",
    "    ground truth and the labels from the k clustering. Using the example dataset:\n",
    "    We have 20 000 items split in 20 categories, which means that a certain category has multiple items. \n",
    "    The idea of best mapping is to take all tuples from ground truth and prediction per item and count their \n",
    "    occurancies. For example (6, 18), 88), 6 being the ground truth and 18 the prediction truth. This \n",
    "    combination has occured 88 times but ((6, 3), 116) has occured 116 times, so at the end the function \n",
    "    will return 6,3 as best map.\n",
    "'''\n",
    "\n",
    "# Mapping Option 1\n",
    "\n",
    "from munkres import Munkres\n",
    "def best_map(L1,L2):\n",
    "    #L1 should be the groundtruth labels and L2 should be the clustering labels we got\n",
    "    Label1 = np.unique(L1)\n",
    "    nClass1 = len(Label1)\n",
    "    Label2 = np.unique(L2)\n",
    "    nClass2 = len(Label2)\n",
    "    nClass = np.maximum(nClass1,nClass2)\n",
    "    G = np.zeros((nClass,nClass))\n",
    "    for i in range(nClass1):\n",
    "        ind_cla1 = L1 == Label1[i]\n",
    "        ind_cla1 = ind_cla1.astype(float)\n",
    "        for j in range(nClass2):\n",
    "            ind_cla2 = L2 == Label2[j]\n",
    "            ind_cla2 = ind_cla2.astype(float)\n",
    "            G[i,j] = np.sum(ind_cla2 * ind_cla1)\n",
    "    m = Munkres()\n",
    "    index = m.compute(-G.T)\n",
    "    index = np.array(index)\n",
    "    c = index[:,1]\n",
    "    newL2 = np.zeros(L2.shape)\n",
    "    for i in range(nClass2):\n",
    "        newL2[L2 == Label2[i]] = Label1[c[i]]\n",
    "    return newL2 \n",
    "\n",
    "\n",
    "# Mapping Option 2\n",
    "\n",
    "import munkres\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "def translateLabels(masterList, listToConvert):    \n",
    "    contMatrix = contingency_matrix(masterList, listToConvert)\n",
    "    labelMatcher = munkres.Munkres()\n",
    "    labelTranlater = labelMatcher.compute(contMatrix.max() - contMatrix)\n",
    "\n",
    "    uniqueLabels1 = list(set(masterList))\n",
    "    uniqueLabels2 = list(set(listToConvert))\n",
    "\n",
    "    tranlatorDict = {}\n",
    "    for thisPair in labelTranlater:\n",
    "        tranlatorDict[uniqueLabels2[thisPair[1]]] = uniqueLabels1[thisPair[0]]\n",
    "\n",
    "    return [tranlatorDict[label] for label in listToConvert]\n",
    "\n",
    "\n",
    "\n",
    "# Mapping Option 3\n",
    "\n",
    "def map_label(true_labels, pred_labels):\n",
    "    label_pair = list(zip(pred_labels, true_labels))\n",
    "    count = tuple(Counter(label_pair).items())  #count the appearance of each pair dict principle\n",
    "    mapping = dict()\n",
    "    n_label = len(np.unique(true_labels))\n",
    "\n",
    "    # map most likely labels from prediction to ground truth\n",
    "\n",
    "    for label in range(n_label):\n",
    "        tuples = [tup for tup in count if tup[0][0] == label]\n",
    "        likely_tuple = max(tuples, key=itemgetter(1))[0] # tuple as input and take the one which appears the most from the list\n",
    "        mapping[likely_tuple[0]] = likely_tuple[1]\n",
    "\n",
    "    pred_labels_mapped = [mapping[x] for x in pred_labels]\n",
    "    return pred_labels_mapped\n",
    "\n",
    "\n",
    "# Evaluate cluster quality - if you have labels\n",
    "\n",
    "def cluster_quality(true_labels, pred_labels, show=True):\n",
    "    h, c, v = metrics.homogeneity_completeness_v_measure(true_labels, pred_labels)\n",
    "    nmi = metrics.normalized_mutual_info_score(true_labels, pred_labels)\n",
    "    rand = metrics.adjusted_rand_score(true_labels, pred_labels)\n",
    "    #pred_labels_mapped = best_map(true_labels,pred_labels) # First variation of Hungarian Method\n",
    "    #pred_labels_mapped = translateLabels(true_labels,pred_labels) # Second variation with Hungarian Method\n",
    "    pred_labels_mapped = map_label(true_labels, pred_labels) # basic func\n",
    "    # all mappings have similar results\n",
    "    acc = metrics.accuracy_score(true_labels, pred_labels_mapped)\n",
    "    '''\n",
    "    if show:\n",
    "        print(\"Homogeneity: %0.3f\" % h)\n",
    "        print(\"Completeness: %0.3f\" % c)\n",
    "        print(\"V-measure: %0.3f\" % v)\n",
    "        print(\"NMI: %0.3f\" % nmi)\n",
    "        print(\"Rand score: %0.3f\" % rand)\n",
    "        print(\"Accuracy: %0.3f\" % acc)\n",
    "        '''\n",
    "    return dict(\n",
    "        homogeneity=round(h,3),\n",
    "        completeness=round(c,3),\n",
    "        vmeasure=round(v,3),\n",
    "        nmi=round(nmi,3),\n",
    "        rand=round(rand,3),\n",
    "        accuracy=round(acc,3),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:20:39.653252Z",
     "start_time": "2019-06-27T22:20:39.627119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 20,000 short texts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "############################\n",
    "# Loading Data\n",
    "############################\n",
    "\n",
    "EMBEDDING_FILE = 'data/GoogleNews-vectors-negative300.bin' # word vectors\n",
    "text_path = 'data/StackOverflow.txt'# data without labels\n",
    "#text_path = 'data/blq.txt'# data without labels - Own Data\n",
    "label_path = 'data/StackOverflow_gnd.txt' # labels per row in the data file\n",
    "\n",
    "with open(text_path) as f:\n",
    "    data = [text.strip() for text in f]\n",
    "\n",
    "with open(label_path) as f:\n",
    "    target = f.readlines()\n",
    "    \n",
    "target = [int(label.rstrip('\\n')) for label in target] # the data has /n at the end of each row\n",
    "\n",
    "print(\"Total: %s short texts\" % format(len(data), \",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:20:40.908287Z",
     "start_time": "2019-06-27T22:20:40.267110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11365 unique tokens.\n",
      "Minumum length: 1\n",
      "Average length: 8\n",
      "Max length: 34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n    pad_sequences is used to ensure that all sequences in a list have the same length. By default this \\n    is done by padding 0 in the beginning of each sequence until each sequence has the same \\n    length as the longest sequence.\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################\n",
    "# Preprocessing\n",
    "############################\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = Tokenizer(char_level=False)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences_full = tokenizer.texts_to_sequences(data) # replace words/tokens with numbers\n",
    "\n",
    "word_index = tokenizer.word_index # get the coresponing word:number dict format\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "MAX_NB_WORDS = len(word_index) # all words - len\n",
    "\n",
    "seq_lens = [len(s) for s in sequences_full] # get the count of words/symbols in the sequence from above\n",
    "print(\"Minumum length: %d\" % min(seq_lens))\n",
    "print(\"Average length: %d\" % np.mean(seq_lens))\n",
    "print(\"Max length: %d\" % max(seq_lens))\n",
    "MAX_SEQUENCE_LENGTH = max(seq_lens)\n",
    "\n",
    "X = pad_sequences(sequences_full, maxlen=MAX_SEQUENCE_LENGTH) # uses the len of the list and max len\n",
    "y = target # we take the target values\n",
    "\n",
    "'''\n",
    "    pad_sequences is used to ensure that all sequences in a list have the same length. By default this \n",
    "    is done by padding 0 in the beginning of each sequence until each sequence has the same \n",
    "    length as the longest sequence.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:21:27.914884Z",
     "start_time": "2019-06-27T22:20:41.430307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing embedding matrix\n",
      "Null word embeddings: 4269\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# Preparing embedding matrix\n",
    "############################\n",
    "\n",
    "\n",
    "print('Preparing embedding matrix')\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index)) + 1\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM)) # Init as 0's and updated if in word2vec\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)\n",
    "    #else:\n",
    "        #print(word)\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:21:33.657144Z",
     "start_time": "2019-06-27T22:21:28.417036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of average embedding:  (20000, 300)\n",
      "(20000, 300)\n",
      "[1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 0. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 1. 0.\n",
      " 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0.\n",
      " 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "# Preparing target using Average embeddings (AE)\n",
    "#################################################\n",
    "Y = {}\n",
    "tfidf_seq = tokenizer.sequences_to_matrix(sequences_full, mode='tfidf') # converting List of sequences (a sequence is a list of integer word indices).\n",
    "# TF-IDF Acc: 0,329\n",
    "binary_seq = tokenizer.sequences_to_matrix(sequences_full, mode='binary') # Acc: 0,458\n",
    "count_seq = tokenizer.sequences_to_matrix(sequences_full, mode='count') # Acc: 0,467\n",
    "frequency_seq = tokenizer.sequences_to_matrix(sequences_full, mode='freq') # Acc: 0452\n",
    "from sklearn.preprocessing import Normalizer\n",
    "normed_value = Normalizer().fit_transform(binary_seq)\n",
    "average_embeddings = np.dot(normed_value, embedding_matrix)\n",
    "Y[\"ae\"] = average_embeddings\n",
    "print(\"Shape of average embedding: \", Y['ae'].shape)\n",
    "\n",
    "\n",
    "# binary Y\n",
    "from sklearn import preprocessing\n",
    "reduction_name = \"ae\"\n",
    "B = preprocessing.Binarizer().fit_transform(Y[reduction_name]) # binarizing the whole value list for ae key (which is the only key)\n",
    "\n",
    "# Shape of last dimension in the CNN\n",
    "TARGET_DIM = B.shape[1]\n",
    "\n",
    "# Example of binarized target vector\n",
    "print(B.shape)\n",
    "print(B[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:21:34.170954Z",
     "start_time": "2019-06-27T22:21:34.160282Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "###############PLAYING-GridSearch#################################\n",
    "# Playing train model\n",
    "################################################\n",
    "\n",
    "# Best accuracy for now\n",
    "\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, Dropout, Activation, concatenate, Input\n",
    "from keras.layers import Embedding, Conv1D, SpatialDropout1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#https://stats.stackexchange.com/questions/240305/where-should-i-place-dropout-layers-in-a-neural-network\n",
    "# the above link has to do with dropout positioning\n",
    "\n",
    "# https://github.com/keras-team/keras/issues/7290\n",
    "# has to do with spatial dropout after embedding layer\n",
    "\n",
    "# https://towardsdatascience.com/review-tompson-cvpr15-spatial-dropout-human-pose-estimation-c7d6a5cecd8c\n",
    "# SpatialDropout again\n",
    "\n",
    "def get_model():\n",
    "    embedding_matrix_copy = embedding_matrix.copy()\n",
    "    trainable_embedding = False\n",
    "    #filters = [2,3,4]\n",
    "    filters = [3,4,5]\n",
    "    # Embedding layer\n",
    "    pretrained_embedding_layer = Embedding(\n",
    "        input_dim=nb_words,\n",
    "        output_dim=EMBEDDING_DIM,\n",
    "        weights=[embedding_matrix],\n",
    "        input_length=MAX_SEQUENCE_LENGTH,\n",
    "    )\n",
    "\n",
    "    # Input\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = pretrained_embedding_layer(sequence_input)\n",
    "    \n",
    "    # DropOut\n",
    "    #x = Dropout(0.2)(embedded_sequences)\n",
    "    spatial_x = SpatialDropout1D(0.2)(embedded_sequences)\n",
    "    #spatial_x = SpatialDropout1D(0.1)(embedded_sequences) # initial but then changed to the one above\n",
    "    # 1st Layer\n",
    "    conv_layers = []\n",
    "    for i in filters:\n",
    "        x = Conv1D(125, i, activation='tanh', padding='same')(spatial_x)\n",
    "        x = GlobalMaxPooling1D()(x)\n",
    "        #x = Dropout(0.2)(x)\n",
    "        conv_layers.append(x)\n",
    "    merged = concatenate(conv_layers)\n",
    "    # Dense\n",
    "    x = Dense(256,activation = 'tanh')(merged)\n",
    "    \n",
    "    # DropOut\n",
    "    x = Dropout(0.2)(x)\n",
    "    #x = Dropout(0.1)(x)# initial but then changed to the one above\n",
    "    # Output\n",
    "    predictions = Dense(TARGET_DIM, activation='sigmoid')(x) \n",
    "    # sigmoid because we want 0,1 for one of the categories\n",
    "    \n",
    "    model = Model(sequence_input, predictions)\n",
    "\n",
    "    model.layers[1].trainable=trainable_embedding #embedding layer\n",
    "\n",
    "    #adam = Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0) #standard for keras\n",
    "    #optimizer = Adam(lr=learn_rate)\n",
    "    \n",
    "    # Loss and Optimizer\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=adam,\n",
    "                  metrics=['accuracy','mae'])\n",
    "    \n",
    "    # Fine-tune embeddings or not\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-25T20:50:12.262087Z",
     "start_time": "2019-06-25T20:50:09.697Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Grid Search with best model\n",
    "# Use scikit-learn to grid search the number of neurons\n",
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.constraints import maxnorm\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=get_model, epochs=50, batch_size=100,verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "\n",
    "#activ = ['relu', 'tanh', 'sigmoid']\n",
    "#optimizers = ['Nadam','Adam']\n",
    "droupou = [0.1,0.2,0.3]\n",
    "#init_mode = ['uniform', 'lecun_uniform']\n",
    "#filters =[100,120]\n",
    "#size = [100,120,125]\n",
    "#filterme = [[3,4,5], [2,3,4]]\n",
    "#batch_size = [200]\n",
    "#epochs = [120]\n",
    "#learn_rate = [0.001, 0.01, 0.02, 0.1]\n",
    "#momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "\n",
    "param_grid = dict(droupout = droupou)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs= -1)\n",
    "grid_result = grid.fit(X, B)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:36:45.613800Z",
     "start_time": "2019-06-27T22:21:34.721070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 34)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 34, 300)      3409800     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 34, 300)      0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 34, 125)      112625      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 34, 125)      150125      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 34, 125)      187625      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_7 (GlobalM (None, 125)          0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_8 (GlobalM (None, 125)          0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 125)          0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 375)          0           global_max_pooling1d_7[0][0]     \n",
      "                                                                 global_max_pooling1d_8[0][0]     \n",
      "                                                                 global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 256)          96256       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 300)          77100       dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,033,531\n",
      "Trainable params: 623,731\n",
      "Non-trainable params: 3,409,800\n",
      "__________________________________________________________________________________________________\n",
      "Train on 16000 samples, validate on 4000 samples\n",
      "Epoch 1/50\n",
      "16000/16000 [==============================] - 13s 844us/step - loss: 0.4983 - acc: 0.7530 - mean_absolute_error: 0.3375 - val_loss: 0.4494 - val_acc: 0.7866 - val_mean_absolute_error: 0.3072\n",
      "Epoch 2/50\n",
      "16000/16000 [==============================] - 13s 842us/step - loss: 0.4229 - acc: 0.8016 - mean_absolute_error: 0.2848 - val_loss: 0.4082 - val_acc: 0.8111 - val_mean_absolute_error: 0.2770\n",
      "Epoch 3/50\n",
      "16000/16000 [==============================] - 14s 898us/step - loss: 0.3915 - acc: 0.8193 - mean_absolute_error: 0.2623 - val_loss: 0.3838 - val_acc: 0.8241 - val_mean_absolute_error: 0.2593\n",
      "Epoch 4/50\n",
      "16000/16000 [==============================] - 14s 881us/step - loss: 0.3725 - acc: 0.8293 - mean_absolute_error: 0.2482 - val_loss: 0.3680 - val_acc: 0.8329 - val_mean_absolute_error: 0.2499\n",
      "Epoch 5/50\n",
      "16000/16000 [==============================] - 14s 904us/step - loss: 0.3597 - acc: 0.8358 - mean_absolute_error: 0.2384 - val_loss: 0.3567 - val_acc: 0.8381 - val_mean_absolute_error: 0.2396\n",
      "Epoch 6/50\n",
      "16000/16000 [==============================] - 14s 873us/step - loss: 0.3502 - acc: 0.8408 - mean_absolute_error: 0.2310 - val_loss: 0.3475 - val_acc: 0.8430 - val_mean_absolute_error: 0.2323\n",
      "Epoch 7/50\n",
      "16000/16000 [==============================] - 16s 972us/step - loss: 0.3430 - acc: 0.8445 - mean_absolute_error: 0.2253 - val_loss: 0.3411 - val_acc: 0.8459 - val_mean_absolute_error: 0.2271\n",
      "Epoch 8/50\n",
      "16000/16000 [==============================] - 15s 914us/step - loss: 0.3369 - acc: 0.8475 - mean_absolute_error: 0.2205 - val_loss: 0.3359 - val_acc: 0.8489 - val_mean_absolute_error: 0.2251\n",
      "Epoch 9/50\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.3323 - acc: 0.8499 - mean_absolute_error: 0.2169 - val_loss: 0.3315 - val_acc: 0.8509 - val_mean_absolute_error: 0.2204\n",
      "Epoch 10/50\n",
      "16000/16000 [==============================] - 22s 1ms/step - loss: 0.3285 - acc: 0.8518 - mean_absolute_error: 0.2137 - val_loss: 0.3274 - val_acc: 0.8532 - val_mean_absolute_error: 0.2187\n",
      "Epoch 11/50\n",
      "16000/16000 [==============================] - 23s 1ms/step - loss: 0.3251 - acc: 0.8536 - mean_absolute_error: 0.2111 - val_loss: 0.3242 - val_acc: 0.8545 - val_mean_absolute_error: 0.2149\n",
      "Epoch 12/50\n",
      "16000/16000 [==============================] - 21s 1ms/step - loss: 0.3219 - acc: 0.8551 - mean_absolute_error: 0.2085 - val_loss: 0.3214 - val_acc: 0.8563 - val_mean_absolute_error: 0.2143\n",
      "Epoch 13/50\n",
      "16000/16000 [==============================] - 21s 1ms/step - loss: 0.3196 - acc: 0.8563 - mean_absolute_error: 0.2065 - val_loss: 0.3188 - val_acc: 0.8571 - val_mean_absolute_error: 0.2109\n",
      "Epoch 14/50\n",
      "16000/16000 [==============================] - 20s 1ms/step - loss: 0.3169 - acc: 0.8577 - mean_absolute_error: 0.2045 - val_loss: 0.3163 - val_acc: 0.8582 - val_mean_absolute_error: 0.2078\n",
      "Epoch 15/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.3153 - acc: 0.8583 - mean_absolute_error: 0.2030 - val_loss: 0.3147 - val_acc: 0.8589 - val_mean_absolute_error: 0.2072\n",
      "Epoch 16/50\n",
      "16000/16000 [==============================] - 19s 1ms/step - loss: 0.3132 - acc: 0.8593 - mean_absolute_error: 0.2015 - val_loss: 0.3131 - val_acc: 0.8597 - val_mean_absolute_error: 0.2049\n",
      "Epoch 17/50\n",
      "16000/16000 [==============================] - 19s 1ms/step - loss: 0.3117 - acc: 0.8603 - mean_absolute_error: 0.2001 - val_loss: 0.3112 - val_acc: 0.8612 - val_mean_absolute_error: 0.2060\n",
      "Epoch 18/50\n",
      "16000/16000 [==============================] - 19s 1ms/step - loss: 0.3100 - acc: 0.8609 - mean_absolute_error: 0.1987 - val_loss: 0.3099 - val_acc: 0.8615 - val_mean_absolute_error: 0.2026\n",
      "Epoch 19/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.3087 - acc: 0.8615 - mean_absolute_error: 0.1977 - val_loss: 0.3083 - val_acc: 0.8622 - val_mean_absolute_error: 0.2021\n",
      "Epoch 20/50\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.3071 - acc: 0.8625 - mean_absolute_error: 0.1965 - val_loss: 0.3076 - val_acc: 0.8625 - val_mean_absolute_error: 0.1997\n",
      "Epoch 21/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.3058 - acc: 0.8631 - mean_absolute_error: 0.1955 - val_loss: 0.3059 - val_acc: 0.8636 - val_mean_absolute_error: 0.2010\n",
      "Epoch 22/50\n",
      "16000/16000 [==============================] - 20s 1ms/step - loss: 0.3049 - acc: 0.8635 - mean_absolute_error: 0.1947 - val_loss: 0.3047 - val_acc: 0.8642 - val_mean_absolute_error: 0.2002\n",
      "Epoch 23/50\n",
      "16000/16000 [==============================] - 20s 1ms/step - loss: 0.3036 - acc: 0.8641 - mean_absolute_error: 0.1938 - val_loss: 0.3037 - val_acc: 0.8645 - val_mean_absolute_error: 0.1982\n",
      "Epoch 24/50\n",
      "16000/16000 [==============================] - 19s 1ms/step - loss: 0.3028 - acc: 0.8646 - mean_absolute_error: 0.1931 - val_loss: 0.3027 - val_acc: 0.8651 - val_mean_absolute_error: 0.1978\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000/16000 [==============================] - 21s 1ms/step - loss: 0.3019 - acc: 0.8649 - mean_absolute_error: 0.1923 - val_loss: 0.3020 - val_acc: 0.8654 - val_mean_absolute_error: 0.1973\n",
      "Epoch 26/50\n",
      "16000/16000 [==============================] - 24s 1ms/step - loss: 0.3009 - acc: 0.8655 - mean_absolute_error: 0.1916 - val_loss: 0.3009 - val_acc: 0.8660 - val_mean_absolute_error: 0.1964\n",
      "Epoch 27/50\n",
      "16000/16000 [==============================] - 19s 1ms/step - loss: 0.2998 - acc: 0.8661 - mean_absolute_error: 0.1908 - val_loss: 0.3001 - val_acc: 0.8663 - val_mean_absolute_error: 0.1958\n",
      "Epoch 28/50\n",
      "16000/16000 [==============================] - 23s 1ms/step - loss: 0.2994 - acc: 0.8662 - mean_absolute_error: 0.1904 - val_loss: 0.2992 - val_acc: 0.8666 - val_mean_absolute_error: 0.1953\n",
      "Epoch 29/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2987 - acc: 0.8667 - mean_absolute_error: 0.1898 - val_loss: 0.2986 - val_acc: 0.8670 - val_mean_absolute_error: 0.1945\n",
      "Epoch 30/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2977 - acc: 0.8671 - mean_absolute_error: 0.1891 - val_loss: 0.2979 - val_acc: 0.8674 - val_mean_absolute_error: 0.1950\n",
      "Epoch 31/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2969 - acc: 0.8674 - mean_absolute_error: 0.1885 - val_loss: 0.2972 - val_acc: 0.8677 - val_mean_absolute_error: 0.1936\n",
      "Epoch 32/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2959 - acc: 0.8681 - mean_absolute_error: 0.1879 - val_loss: 0.2969 - val_acc: 0.8678 - val_mean_absolute_error: 0.1933\n",
      "Epoch 33/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2956 - acc: 0.8682 - mean_absolute_error: 0.1875 - val_loss: 0.2959 - val_acc: 0.8682 - val_mean_absolute_error: 0.1923\n",
      "Epoch 34/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2950 - acc: 0.8684 - mean_absolute_error: 0.1870 - val_loss: 0.2954 - val_acc: 0.8685 - val_mean_absolute_error: 0.1925\n",
      "Epoch 35/50\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.2946 - acc: 0.8686 - mean_absolute_error: 0.1867 - val_loss: 0.2949 - val_acc: 0.8687 - val_mean_absolute_error: 0.1914\n",
      "Epoch 36/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2938 - acc: 0.8691 - mean_absolute_error: 0.1861 - val_loss: 0.2945 - val_acc: 0.8689 - val_mean_absolute_error: 0.1917\n",
      "Epoch 37/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2935 - acc: 0.8691 - mean_absolute_error: 0.1858 - val_loss: 0.2939 - val_acc: 0.8691 - val_mean_absolute_error: 0.1907\n",
      "Epoch 38/50\n",
      "16000/16000 [==============================] - 19s 1ms/step - loss: 0.2930 - acc: 0.8694 - mean_absolute_error: 0.1855 - val_loss: 0.2937 - val_acc: 0.8694 - val_mean_absolute_error: 0.1918\n",
      "Epoch 39/50\n",
      "16000/16000 [==============================] - 21s 1ms/step - loss: 0.2926 - acc: 0.8696 - mean_absolute_error: 0.1852 - val_loss: 0.2928 - val_acc: 0.8695 - val_mean_absolute_error: 0.1901\n",
      "Epoch 40/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2916 - acc: 0.8701 - mean_absolute_error: 0.1845 - val_loss: 0.2926 - val_acc: 0.8697 - val_mean_absolute_error: 0.1912\n",
      "Epoch 41/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2909 - acc: 0.8703 - mean_absolute_error: 0.1841 - val_loss: 0.2917 - val_acc: 0.8703 - val_mean_absolute_error: 0.1901\n",
      "Epoch 42/50\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.2905 - acc: 0.8705 - mean_absolute_error: 0.1838 - val_loss: 0.2914 - val_acc: 0.8702 - val_mean_absolute_error: 0.1893\n",
      "Epoch 43/50\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.2903 - acc: 0.8708 - mean_absolute_error: 0.1835 - val_loss: 0.2912 - val_acc: 0.8704 - val_mean_absolute_error: 0.1897\n",
      "Epoch 44/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2898 - acc: 0.8712 - mean_absolute_error: 0.1831 - val_loss: 0.2903 - val_acc: 0.8709 - val_mean_absolute_error: 0.1888\n",
      "Epoch 45/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2895 - acc: 0.8710 - mean_absolute_error: 0.1829 - val_loss: 0.2902 - val_acc: 0.8708 - val_mean_absolute_error: 0.1879\n",
      "Epoch 46/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2890 - acc: 0.8713 - mean_absolute_error: 0.1826 - val_loss: 0.2900 - val_acc: 0.8707 - val_mean_absolute_error: 0.1878\n",
      "Epoch 47/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2889 - acc: 0.8713 - mean_absolute_error: 0.1824 - val_loss: 0.2894 - val_acc: 0.8711 - val_mean_absolute_error: 0.1877\n",
      "Epoch 48/50\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.2884 - acc: 0.8717 - mean_absolute_error: 0.1820 - val_loss: 0.2891 - val_acc: 0.8710 - val_mean_absolute_error: 0.1868\n",
      "Epoch 49/50\n",
      "16000/16000 [==============================] - 17s 1ms/step - loss: 0.2880 - acc: 0.8719 - mean_absolute_error: 0.1818 - val_loss: 0.2886 - val_acc: 0.8715 - val_mean_absolute_error: 0.1878\n",
      "Epoch 50/50\n",
      "16000/16000 [==============================] - 18s 1ms/step - loss: 0.2876 - acc: 0.8721 - mean_absolute_error: 0.1815 - val_loss: 0.2884 - val_acc: 0.8716 - val_mean_absolute_error: 0.1873\n",
      "Sample shape: (20000, 256)\n"
     ]
    }
   ],
   "source": [
    "# 25 epoch and 80 batch = 50.3 accuracy\n",
    "nb_epoch = 50\n",
    "checkpoint = ModelCheckpoint('models/weights.{epoch:03d}-{val_acc:.4f}.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto')\n",
    "model = get_model()\n",
    "history = model.fit(X, B, validation_split=0.2,\n",
    "              epochs=nb_epoch, batch_size=100, verbose=1, shuffle=True)\n",
    "\n",
    "# create model that gives penultimate layer (предпоследно)\n",
    "input1 = model.layers[0].input\n",
    "output = model.layers[-2].output\n",
    "\n",
    "model_penultimate = Model(input1, output)\n",
    "\n",
    "# inference of penultimate layer\n",
    "H = model_penultimate.predict(X)\n",
    "#H = model.predict(X)\n",
    "print(\"Sample shape: {}\".format(H.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:36:46.620228Z",
     "start_time": "2019-06-27T22:36:46.435323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:36:47.553909Z",
     "start_time": "2019-06-27T22:36:47.371594Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:36:54.872442Z",
     "start_time": "2019-06-27T22:36:48.294228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 20\n",
      "[12 12  6 ...  0  0 16]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "true_labels = y\n",
    "n_clusters = len(np.unique(y))\n",
    "print(\"Number of classes: %d\" % n_clusters)\n",
    "km = KMeans(n_clusters=n_clusters, n_jobs=10)\n",
    "result = dict()\n",
    "V = normalize(H, norm='l2')\n",
    "km.fit(V)\n",
    "pred = km.labels_\n",
    "pred1 = km.cluster_centers_\n",
    "print(pred)\n",
    "a = cluster_quality(true_labels, pred)\n",
    "#np.save(\"pred.npy\", pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:36:55.610265Z",
     "start_time": "2019-06-27T22:36:55.606734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'homogeneity': 0.455, 'completeness': 0.481, 'vmeasure': 0.468, 'nmi': 0.468, 'rand': 0.282, 'accuracy': 0.508}\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running clusterS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:44:29.506267Z",
     "start_time": "2019-06-27T22:36:56.306456Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 0 was completed!\n",
      "Run 1 was completed!\n",
      "Run 2 was completed!\n",
      "Run 3 was completed!\n",
      "Run 4 was completed!\n",
      "Run 5 was completed!\n",
      "Run 6 was completed!\n",
      "Run 7 was completed!\n",
      "Run 8 was completed!\n",
      "Run 9 was completed!\n",
      "Run 10 was completed!\n",
      "Run 11 was completed!\n",
      "Run 12 was completed!\n",
      "Run 13 was completed!\n",
      "Run 14 was completed!\n",
      "Run 15 was completed!\n",
      "Run 16 was completed!\n",
      "Run 17 was completed!\n",
      "Run 18 was completed!\n",
      "Run 19 was completed!\n",
      "Run 20 was completed!\n",
      "Run 21 was completed!\n",
      "Run 22 was completed!\n",
      "Run 23 was completed!\n",
      "Run 24 was completed!\n",
      "Run 25 was completed!\n",
      "Run 26 was completed!\n",
      "Run 27 was completed!\n",
      "Run 28 was completed!\n",
      "Run 29 was completed!\n",
      "Run 30 was completed!\n",
      "Run 31 was completed!\n",
      "Run 32 was completed!\n",
      "Run 33 was completed!\n",
      "Run 34 was completed!\n",
      "Run 35 was completed!\n",
      "Run 36 was completed!\n",
      "Run 37 was completed!\n",
      "Run 38 was completed!\n",
      "Run 39 was completed!\n",
      "Run 40 was completed!\n",
      "Run 41 was completed!\n",
      "Run 42 was completed!\n",
      "Run 43 was completed!\n",
      "Run 44 was completed!\n",
      "Run 45 was completed!\n",
      "Run 46 was completed!\n",
      "Run 47 was completed!\n",
      "Run 48 was completed!\n",
      "Run 49 was completed!\n",
      "Run 50 was completed!\n",
      "Run 51 was completed!\n",
      "Run 52 was completed!\n",
      "Run 53 was completed!\n",
      "Run 54 was completed!\n",
      "Run 55 was completed!\n",
      "Run 56 was completed!\n",
      "Run 57 was completed!\n",
      "Run 58 was completed!\n",
      "Run 59 was completed!\n",
      "Run 60 was completed!\n",
      "Run 61 was completed!\n",
      "Run 62 was completed!\n",
      "Run 63 was completed!\n",
      "Run 64 was completed!\n",
      "Run 65 was completed!\n",
      "Run 66 was completed!\n",
      "Run 67 was completed!\n",
      "Run 68 was completed!\n",
      "Run 69 was completed!\n",
      "Run 70 was completed!\n",
      "Run 71 was completed!\n",
      "Run 72 was completed!\n",
      "Run 73 was completed!\n",
      "Run 74 was completed!\n",
      "Run 75 was completed!\n",
      "Run 76 was completed!\n",
      "Run 77 was completed!\n",
      "Run 78 was completed!\n",
      "Run 79 was completed!\n",
      "Run 80 was completed!\n",
      "Run 81 was completed!\n",
      "Run 82 was completed!\n",
      "Run 83 was completed!\n",
      "Run 84 was completed!\n",
      "Run 85 was completed!\n",
      "Run 86 was completed!\n",
      "Run 87 was completed!\n",
      "Run 88 was completed!\n",
      "Run 89 was completed!\n",
      "Run 90 was completed!\n",
      "Run 91 was completed!\n",
      "Run 92 was completed!\n",
      "Run 93 was completed!\n",
      "Run 94 was completed!\n",
      "Run 95 was completed!\n",
      "Run 96 was completed!\n",
      "Run 97 was completed!\n",
      "Run 98 was completed!\n",
      "Run 99 was completed!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# clustering loop\n",
    "true_labels = y\n",
    "n_clusters = len(np.unique(y))\n",
    "#print(\"Number of classes: %d\" % n_clusters)\n",
    "km = KMeans(n_clusters=n_clusters, n_jobs=10)\n",
    "result = dict()\n",
    "V = normalize(H, norm='l2')\n",
    "df = pd.DataFrame()\n",
    "for i in range(100):\n",
    "    km.fit(V)\n",
    "    pred = km.labels_\n",
    "    pred1 = km.cluster_centers_\n",
    "    #print(pred)\n",
    "    a = cluster_quality(true_labels, pred)\n",
    "    df = df.append([a],ignore_index=True)\n",
    "    print('Run {} was completed!'.format(i))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T09:14:37.188975Z",
     "start_time": "2019-06-26T09:14:34.619Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## OLD\n",
    "'''\n",
    "import statistics \n",
    "# round up this and the ones below in function to end up with a table for the paper\n",
    "dfToList_NMI = df['nmi'].tolist()\n",
    "dfToList_Acc = df['accuracy'].tolist()\n",
    "lenListACC = len(dfToList_Acc)\n",
    "lenListACC = len(dfToList_NMI)\n",
    "sumACC = 0\n",
    "sumNMI = 0\n",
    "for i in dfToList_Acc:\n",
    "    sumACC += i\n",
    "df['average_acc'] = round(sumACC/lenListACC,3)\n",
    "df['diff_acc'] = df.apply(lambda x: (x['accuracy'] - x['average_acc']), axis=1)\n",
    "df['standard_dev'] = df.apply(lambda x: (x['accuracy'] - x['average_acc']), axis=1)\n",
    "\n",
    "for a in dfToList_NMI:\n",
    "    sumNMI +=a\n",
    "    df['average_nmi'] = round(sumNMI/lenListACC,3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T14:17:50.456286Z",
     "start_time": "2019-06-21T14:17:50.430540Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# using tfidf\n",
    "df_tfidf = df\n",
    "max_acc = df_tfidf['accuracy'].max() # 0,581\n",
    "print('Max accuracy is: {}'.format(max_acc))\n",
    "min_acc = df_tfidf['accuracy'].min() # 0.463\n",
    "print('Min accuracy is: {}'.format(min_acc))\n",
    "average_acc = df_tfidf['average_acc'].max() # 0.514\n",
    "print('Average accuracy is: {}'.format(average_acc))\n",
    "standard_dev_acc = statistics.stdev(dfToList_Acc)\n",
    "print('Standar deviation (Accuracy) is: {}'.format(standard_dev_acc))\n",
    "standard_dev_nmi = statistics.stdev(dfToList_NMI)\n",
    "print('Standar deviation (NMI) is: {}'.format(standard_dev_nmi))\n",
    "df_tfidf.to_csv('100cluster_TF-IDFBased.csv')\n",
    "df_tfidf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-26T07:37:09.312613Z",
     "start_time": "2019-06-26T07:37:09.284451Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# using count\n",
    "import statistics \n",
    "df_count = df\n",
    "max_acc = df_count['accuracy'].max() # 0,581\n",
    "print('Max accuracy is: {}'.format(max_acc))\n",
    "min_acc = df_count['accuracy'].min() # 0.463\n",
    "print('Min accuracy is: {}'.format(min_acc))\n",
    "average_acc = df_count['accuracy'].mean() # 0.514\n",
    "print('Average Accuracy is: {}'.format(average_acc))\n",
    "average_nmi = df_count['nmi'].mean() # 0.514\n",
    "print('Average NMI is: {}'.format(average_nmi))\n",
    "standard_dev_acc = statistics.stdev(df_count['accuracy'])\n",
    "print('Standar deviation (Accuracy) is: {}'.format(standard_dev_acc))\n",
    "standard_dev_nmi = statistics.stdev(df_count['nmi'])\n",
    "print('Standar deviation (NMI) is: {}'.format(standard_dev_nmi))\n",
    "df_count.to_csv('100cluster_countBased.csv')\n",
    "df_count.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-27T22:44:30.363100Z",
     "start_time": "2019-06-27T22:44:30.323879Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max accuracy is: 63.7\n",
      "Min accuracy is: 47.3\n",
      "Average Accuracy is: 53.412\n",
      "Average NMI is: 49.56000000000002\n",
      "Standar deviation (Accuracy) is: 2.6352421160305193\n",
      "Standar deviation (NMI) is: 2.2714744021441144\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>completeness</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>nmi</th>\n",
       "      <th>rand</th>\n",
       "      <th>vmeasure</th>\n",
       "      <th>Normal_ACC</th>\n",
       "      <th>Normal_NMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.552</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.496</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.509</td>\n",
       "      <td>55.2</td>\n",
       "      <td>50.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.536</td>\n",
       "      <td>0.505</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.492</td>\n",
       "      <td>53.6</td>\n",
       "      <td>49.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.517</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.488</td>\n",
       "      <td>51.7</td>\n",
       "      <td>48.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.492</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.465</td>\n",
       "      <td>49.2</td>\n",
       "      <td>46.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.550</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.311</td>\n",
       "      <td>0.509</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  completeness  homogeneity    nmi   rand  vmeasure  Normal_ACC  \\\n",
       "0     0.552         0.523        0.496  0.509  0.319     0.509        55.2   \n",
       "1     0.536         0.505        0.480  0.492  0.301     0.492        53.6   \n",
       "2     0.517         0.503        0.473  0.488  0.295     0.488        51.7   \n",
       "3     0.492         0.480        0.451  0.465  0.271     0.465        49.2   \n",
       "4     0.550         0.523        0.495  0.509  0.311     0.509        55.0   \n",
       "\n",
       "   Normal_NMI  \n",
       "0        50.9  \n",
       "1        49.2  \n",
       "2        48.8  \n",
       "3        46.5  \n",
       "4        50.9  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using binary - new like count\n",
    "\n",
    "import statistics \n",
    "df_binary = df\n",
    "df_binary['Normal_ACC'] = df_binary['accuracy'].map(lambda a: a * 100)\n",
    "df_binary['Normal_NMI'] = df_binary['nmi'].map(lambda a: a * 100)\n",
    "\n",
    "max_acc = df_binary['Normal_ACC'].max() # 0,581\n",
    "print('Max accuracy is: {}'.format(max_acc))\n",
    "\n",
    "min_acc = df_binary['Normal_ACC'].min() # 0.463\n",
    "print('Min accuracy is: {}'.format(min_acc))\n",
    "\n",
    "average_acc = df_binary['Normal_ACC'].mean() # 0.514\n",
    "print('Average Accuracy is: {}'.format(average_acc))\n",
    "\n",
    "average_nmi = df_binary['Normal_NMI'].mean() # 0.514\n",
    "print('Average NMI is: {}'.format(average_nmi))\n",
    "\n",
    "standard_dev_acc = statistics.stdev(df_binary['Normal_ACC'])\n",
    "print('Standar deviation (Accuracy) is: {}'.format(standard_dev_acc))\n",
    "\n",
    "standard_dev_nmi = statistics.stdev(df_binary['Normal_NMI'])\n",
    "print('Standar deviation (NMI) is: {}'.format(standard_dev_nmi))\n",
    "\n",
    "df_binary.to_csv('100cluster_BinaryBased.csv')\n",
    "df_binary.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T12:43:19.230196Z",
     "start_time": "2019-06-21T12:43:19.186013Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# using frequency\n",
    "df_freq = df\n",
    "max_acc = df_freq['accuracy'].max() # 0,581\n",
    "print('Max accuracy is: {}'.format(max_acc))\n",
    "min_acc = df_freq['accuracy'].min() # 0.463\n",
    "print('Min accuracy is: {}'.format(min_acc))\n",
    "average_acc = df_freq['average_acc'].max() # 0.514\n",
    "print('Average accuracy is: {}'.format(average_acc))\n",
    "standard_dev_acc = statistics.stdev(dfToList_Acc)\n",
    "print('Standar deviation (Accuracy) is: {}'.format(standard_dev_acc))\n",
    "standard_dev_nmi = statistics.stdev(dfToList_NMI)\n",
    "print('Standar deviation (NMI) is: {}'.format(standard_dev_nmi))\n",
    "df_freq.to_csv('100cluster_FreqBased.csv')\n",
    "df_freq.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-24T11:52:42.091702Z",
     "start_time": "2019-06-24T11:52:42.056122Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# using binary\n",
    "df_binary = df\n",
    "max_acc = df_binary['accuracy'].max() # 0,581\n",
    "print('Max accuracy is: {}'.format(max_acc))\n",
    "min_acc = df_binary['accuracy'].min() # 0.463\n",
    "print('Min accuracy is: {}'.format(min_acc))\n",
    "average_acc = df_binary['average_acc'].max() # 0.514\n",
    "print('Average accuracy is: {}'.format(average_acc))\n",
    "standard_dev_acc = statistics.stdev(dfToList_Acc)\n",
    "print('Standar deviation (Accuracy) is: {}'.format(standard_dev_acc))\n",
    "standard_dev_nmi = statistics.stdev(dfToList_NMI)\n",
    "print('Standar deviation (NMI) is: {}'.format(standard_dev_nmi))\n",
    "df_binary.to_csv('100cluster_BinaryBased.csv')\n",
    "df_binary.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Save/Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-21T07:30:36.749761Z",
     "start_time": "2019-06-21T07:30:36.392013Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "# Saving Model and weiths\n",
    "# serialize model to JSON\n",
    "'''\n",
    "model_json = model.to_json()\n",
    "with open(\"model_55%.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_55%.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "'''\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model_55%_StackData.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_55%_StackData.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# Evaluate\n",
    "\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144px",
    "left": "1069px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
